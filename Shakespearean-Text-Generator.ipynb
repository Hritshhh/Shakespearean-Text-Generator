{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shakespearean-Text-Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VESCmNeiRe77",
        "_XAOe83ORa7F",
        "5IUKqwPMksoY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFJZTttlQcJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VESCmNeiRe77",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOMWeFL3Bqx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  \"\"\"Function to load the dataset\"\"\"\n",
        "  with open('shakespeare-2.txt', mode='r', encoding='utf-8') as f:\n",
        "    data = f.read()\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYPxdnc8EuOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data()\n",
        "distinct_chars = sorted(list(set(data))) # The vocabulary\n",
        "# char <===> index Mappings\n",
        "char_to_idx = dict((c, i) for i, c in enumerate(distinct_chars))\n",
        "idx_to_char = dict((i, c) for i, c in enumerate(distinct_chars))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1MgZw98GmvK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b58cec46-71f9-4190-c195-8d1b8af3b9d3"
      },
      "source": [
        "# Define constants\n",
        "N_seq = 50 # Length of the input sequence to be fed\n",
        "N_data = len(data)\n",
        "N_vocab = len(distinct_chars)\n",
        "print(N_data, N_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99993 62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7r5_KljN2ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "for i in range(0, N_data - N_seq, 1):\n",
        "  # Given x of 100 charcters (Input Sequence), predict the next character y (Conditional Probability)\n",
        "\tx = data[i:i+N_seq]\n",
        "\ty = data[i+N_seq]\n",
        "\tx_train.append([char_to_idx[x_i] for x_i in x])\n",
        "\ty_train.append(char_to_idx[y])\n",
        "\n",
        "m = len(x_train)\n",
        "assert m == len(y_train), \"Length mismatch error\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPQkosyvnwrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# OHE the input data:\n",
        "for i in range(m):\n",
        "  x_train[i] = to_categorical(x_train[i], num_classes=N_vocab)\n",
        "\n",
        "# OHE the output values\n",
        "y_train = to_categorical(y_train, num_classes=N_vocab)\n",
        "\n",
        "# Reshaping x_train to be [samples, timesteps, features]\n",
        "x_train = np.array(x_train).reshape(m, N_seq, N_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XAOe83ORa7F",
        "colab_type": "text"
      },
      "source": [
        "## The LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlrnOhJGRE2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(512, input_shape=x_train[0].shape, return_sequences=True))\n",
        "  model.add(LSTM(512, return_sequences=True))\n",
        "  model.add(LSTM(512))\n",
        "  model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BuTjQHeSdGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeELtmpcRGMW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c90ef2c8-fc7a-41bf-d443-91507fe6755d"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Callbacks:\n",
        "PATH_SAVE = \"shakespearean_generator_2.h5\"\n",
        "checkpoint = ModelCheckpoint(PATH_SAVE, monitor='loss', mode='min')\n",
        "cb_list = [checkpoint]\n",
        "\n",
        "# Fitting\n",
        "history = model.fit(x_train, y_train, epochs=30, batch_size=128, callbacks=cb_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 2.9471\n",
            "Epoch 2/30\n",
            "99943/99943 [==============================] - 382s 4ms/step - loss: 2.6915\n",
            "Epoch 3/30\n",
            "99943/99943 [==============================] - 382s 4ms/step - loss: 2.1866\n",
            "Epoch 4/30\n",
            "99943/99943 [==============================] - 381s 4ms/step - loss: 2.0075\n",
            "Epoch 5/30\n",
            "99943/99943 [==============================] - 383s 4ms/step - loss: 1.8720\n",
            "Epoch 6/30\n",
            "99943/99943 [==============================] - 382s 4ms/step - loss: 1.7658\n",
            "Epoch 7/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 1.6693\n",
            "Epoch 8/30\n",
            "99943/99943 [==============================] - 385s 4ms/step - loss: 1.5929\n",
            "Epoch 9/30\n",
            "99943/99943 [==============================] - 385s 4ms/step - loss: 1.5241\n",
            "Epoch 10/30\n",
            "99943/99943 [==============================] - 387s 4ms/step - loss: 1.4610\n",
            "Epoch 11/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 1.3991\n",
            "Epoch 12/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 1.3428\n",
            "Epoch 13/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 1.2918\n",
            "Epoch 14/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 1.2343\n",
            "Epoch 15/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 1.1786\n",
            "Epoch 16/30\n",
            "99943/99943 [==============================] - 385s 4ms/step - loss: 1.1204\n",
            "Epoch 17/30\n",
            "99943/99943 [==============================] - 383s 4ms/step - loss: 1.0597\n",
            "Epoch 18/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 0.9999\n",
            "Epoch 19/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 0.9388\n",
            "Epoch 20/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 0.8728\n",
            "Epoch 21/30\n",
            "99943/99943 [==============================] - 385s 4ms/step - loss: 0.8052\n",
            "Epoch 22/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 0.7397\n",
            "Epoch 23/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 0.6678\n",
            "Epoch 24/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 0.6000\n",
            "Epoch 25/30\n",
            "99943/99943 [==============================] - 387s 4ms/step - loss: 0.5311\n",
            "Epoch 26/30\n",
            "99943/99943 [==============================] - 389s 4ms/step - loss: 0.4670\n",
            "Epoch 27/30\n",
            "99943/99943 [==============================] - 389s 4ms/step - loss: 0.4048\n",
            "Epoch 28/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 0.3459\n",
            "Epoch 29/30\n",
            "99943/99943 [==============================] - 385s 4ms/step - loss: 0.2929\n",
            "Epoch 30/30\n",
            "99943/99943 [==============================] - 387s 4ms/step - loss: 0.2506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IUKqwPMksoY",
        "colab_type": "text"
      },
      "source": [
        "## Generating Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_HCLQZap_cH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(seed, ohed_seed, N_chars):\n",
        "  x0 = ohed_seed.copy()\n",
        "  generated_sentence = seed.copy()\n",
        "  for _ in range(N_chars):\n",
        "    x = np.array(x0).reshape(1, N_seq, N_vocab)\n",
        "    probabilities = model.predict(x)\n",
        "    idx = np.random.choice(N_vocab, p=probabilities.ravel())\n",
        "    ohed_idx = to_categorical(idx, num_classes=N_vocab)\n",
        "    x0.append(ohed_idx)\n",
        "    generated_sentence.append(idx)\n",
        "    # Select the next sequence\n",
        "    x0 = x0[1:]\n",
        "  return generated_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W11086BnqUAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3fd4516-378e-4f15-a2f0-298f94b94fa2"
      },
      "source": [
        "initial_word = \"YOUR AWESOME CHARACTER:\"\n",
        "\n",
        "chars_input = set(list(initial_word))\n",
        "chars_valid = set(distinct_chars)\n",
        "invalid_chars = chars_input.difference(chars_valid) # chars_input - chars_valid\n",
        "if invalid_chars:\n",
        "  raise SyntaxError(\"Input word contains invalid characters.\")\n",
        "\n",
        "# Truncate larger words\n",
        "if len(initial_word) > N_seq:\n",
        "  initial_word = initial_word[N_seq:] \n",
        "\n",
        "# Pad small words with spaces\n",
        "N_pad = max(N_seq - len(initial_word), 0)\n",
        "initial_word = ' '*N_pad + initial_word\n",
        "\n",
        "print(\"The initial word is : {}\".format(initial_word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The initial word is :                            YOUR AWESOME CHARACTER:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7EwOde3YOtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = [char_to_idx[character] for character in initial_word]\n",
        "ohed_seed = list(to_categorical(seed, num_classes=N_vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFJibll6YMJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_sentence = generate(seed, ohed_seed, 500)[N_pad:] # Remove the prepended padding, if any"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb0_yaGbcJiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "88a92540-1df9-4342-fe97-ac991cd405d4"
      },
      "source": [
        "generated_sentence = ''.join([idx_to_char[i] for i in generated_sentence])\n",
        "print(generated_sentence) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "YOUR AWESOME CHARACTER:\n",
            "But there are I repont I show anged and too: I bring them.\n",
            "\n",
            "SEBASTIAN:\n",
            "Wine, my bear them! I Dun!\n",
            "\n",
            "TITUS ANDR:\n",
            "Then let this first I good lord; where it not his sender\n",
            "goolinar and putther that themselves in she should\n",
            "Of this joylly down from the world.\n",
            "\n",
            "OTiz:\n",
            "It is some serve, I would not wonder queen.\n",
            "\n",
            "First Servingman:\n",
            "By Lord HasiN, if vire I should ever\n",
            "Do golding sholl be done. This bumd to die, and inforsure no leisure\n",
            "Bamses he should with with a knight, purpereces,\n",
            "There are I see the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viMk0DxrLsRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('shakespeare_final.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}